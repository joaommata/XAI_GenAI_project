{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Responsible AI: XAI GenAI project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Background\n",
    "\n",
    "\n",
    "\n",
    "Based on the previous lessons on explainability, post-hoc methods are used to explain the model, such as saliency map, SmoothGrad, LRP, LIME, and SHAP. Take LRP (Layer Wise Relevance Propagation) as an example; it highlights the most relevant pixels to obtain a prediction of the class \"cat\" by backpropagating the relevance. (image source: [Montavon et. al (2016)](https://giorgiomorales.github.io/Layer-wise-Relevance-Propagation-in-Pytorch/))\n",
    "\n",
    "<!-- %%[markdown] -->\n",
    "![LRP example](images/catLRP.jpg)\n",
    "\n",
    "Another example is about text sentiment classification, here we show a case of visualizing the importance of words given the prediction of 'positive':\n",
    "\n",
    "![text example](images/textGradL2.png)\n",
    "\n",
    "where the words highlight with darker colours indicate to be more critical in predicting the sentence to be 'positive' in sentiment.\n",
    "More examples could be found [here](http://34.160.227.66/?models=sst2-tiny&dataset=sst_dev&hidden_modules=Explanations_Attention&layout=default).\n",
    "\n",
    "Both cases above require the class or the prediction of the model. But:\n",
    "\n",
    "***How do you explain a model that does not predict but generates?***\n",
    "\n",
    "In this project, we will work on explaining the generative model based on the dependency between words. We will first look at a simple example, and using Point-wise Mutual Information (PMI) to compute the saliency map of the sentence. After that we will contruct the expereiment step by step, followed by exercises and questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A simple example to start with\n",
    "Given a sample sentence: \n",
    "> *Tokyo is the capital city of Japan.* \n",
    "\n",
    "We are going to explain this sentence by finding the dependency using a saliency map between words.\n",
    "The dependency of two words in the sentence could be measured by [Point-wise mutual information (PMI)](https://en.wikipedia.org/wiki/Pointwise_mutual_information): \n",
    "\n",
    "\n",
    "Mask two words out, e.g. \n",
    "> \\[MASK-1\\] is the captial city of \\[MASK-2\\].\n",
    "\n",
    "\n",
    "Ask the generative model to fill in the sentence 10 times, and we have:\n",
    "\n",
    "| MASK-1      | MASK-2 |\n",
    "| ----------- | ----------- |\n",
    "|    tokyo   |     japan   |\n",
    "|  paris  |     france    |\n",
    "|  london  |     england    |\n",
    "|  paris  |     france    |\n",
    "|  beijing |  china |\n",
    "|    tokyo   |     japan   |\n",
    "|  paris  |     france    |\n",
    "|  paris  |     france    |\n",
    "|  london  |     england    |\n",
    "|  beijing |  china |\n",
    "\n",
    "PMI is calculated by: \n",
    "\n",
    "$PMI(x,y)=log_2⁡ \\frac{p(\\{x,y\\}| s-\\{x,y\\})}{P(\\{x\\}|s-\\{x,y\\})P(\\{y\\}|s-\\{x,y\\})}$\n",
    "\n",
    "where $x$, $y$ represents the words that we masked out, $s$ represents the setence, and $s-\\{x,y\\}$ represents the sentences tokens after removing the words $x$ and $y$.\n",
    "\n",
    "In this example we have $PMI(Tokyo, capital) = log_2 \\frac{0.2}{0.2 * 0.2} = 2.32$\n",
    "\n",
    "Select an interesting word in the sentences; we can now compute the PMI between all other words and the chosen word using the generative model:\n",
    "(Here, we use a longer sentence and run 20 responses per word.)\n",
    "![](images/resPMI.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation\n",
    "### 2.1 Conda enviroment\n",
    "\n",
    "```\n",
    "conda env create -f environment.yml\n",
    "conda activate xai_llm\n",
    "```\n",
    "\n",
    "\n",
    "### 2.2 Download the offline LLM\n",
    "\n",
    "We use the offline LLM model from hugging face. It's approximately 5 GB.\n",
    "Download it using the comman below, and save it under `./models/`.\n",
    "```\n",
    "huggingface-cli download TheBloke/openchat-3.5-0106-GGUF openchat-3.5-0106.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\n",
    "# credit to https://huggingface.co/TheBloke/openchat-3.5-0106-GGUF\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mask the sentence and get the responses from LLM\n",
    "### 3.1 Get the input sentence\n",
    "\n",
    "**Remember to change the anchor word index when changing the input sentence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed for consistency, so that every run uses the same sentence\n",
    "# def get_input():\n",
    "    # ideally this reads inputs from a file, now it just takes an input\n",
    "    #return input(\"Enter a sentence: \")\n",
    "    \n",
    "# Cell 23 - Reset the sentence\n",
    "sentence = \"doctors assess symptoms to diagnose diseases\"\n",
    "\n",
    "anchor_word_idx = 0 # the index of the interested word\n",
    "prompts_per_word = 20 # number of generated responses  \n",
    "\n",
    "#sentence = get_input()\n",
    "print(\"Sentence: \", sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "from models.ChatModel import ChatModel\n",
    "model_name = \"openchat\"\n",
    "model = ChatModel(model_name)\n",
    "print(f\"Model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Run the prompts and get all the responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.command_generator import generate_prompts, prefix_prompt\n",
    "from tools.evaluate_response import get_replacements\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_prompts(model, sentence, anchor_idx, prompts_per_word=20):\n",
    "    prompts = generate_prompts(sentence, anchor_idx)\n",
    "    all_replacements = []\n",
    "    for prompt in prompts:\n",
    "        replacements = []\n",
    "        for _ in tqdm(\n",
    "            range(prompts_per_word),\n",
    "            desc=f\"Input: {prompt}\",\n",
    "        ):\n",
    "            response = model.get_response(\n",
    "                prefix_prompt(prompt),\n",
    "            ).strip()\n",
    "            if response:\n",
    "                replacement = get_replacements(prompt, response)\n",
    "                if replacement:\n",
    "                    replacements.append(replacement)\n",
    "        if len(replacements) > 0:\n",
    "            all_replacements.append(replacements)\n",
    "    return all_replacements\n",
    "\n",
    "all_responses = run_prompts(model, sentence, anchor_word_idx, prompts_per_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize responses\n",
    "all_responses[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load responses\n",
    "import json\n",
    "input_file = \"responses.json\"\n",
    "with open(input_file, \"r\") as f:\n",
    "    all_responses = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 EXERCISE: compute the PMI for each word\n",
    "\n",
    "$PMI(x,y)=log_2⁡ \\frac{p(\\{x,y\\}| s-\\{x,y\\})}{P(\\{x\\}|s-\\{x,y\\})P(\\{y\\}|s-\\{x,y\\})}$\n",
    "\n",
    "* Compute the $P(x)$, $P(y)$ and $P(x,y)$ first and print it out.\n",
    "* Compute the PMI for each word.\n",
    "* Visualize the result by coloring. Tips: you might need to normalize the result first. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "\n",
    "def compute_pmi(sentence, all_responses, anchor_idx):\n",
    "    \"\"\"Compute PMI between anchor word and each other word.\"\"\"\n",
    "    words = sentence.lower().split()\n",
    "    anchor_word = words[anchor_idx]\n",
    "    pmi_scores = {}\n",
    "    \n",
    "    for other_idx in range(len(words)):\n",
    "        if other_idx == anchor_idx:\n",
    "            continue\n",
    "        \n",
    "        # Get pattern index (skips anchor position)\n",
    "        pattern_idx = other_idx if other_idx < anchor_idx else other_idx - 1\n",
    "        if pattern_idx >= len(all_responses):\n",
    "            continue\n",
    "            \n",
    "        responses = all_responses[pattern_idx]\n",
    "        if not responses:\n",
    "            continue\n",
    "        \n",
    "        # Extract anchor and other word replacements\n",
    "        anchor_replacements = [r[0].lower() for r in responses if len(r) == 2]\n",
    "        other_replacements = [r[1].lower() for r in responses if len(r) == 2]\n",
    "        total = len(anchor_replacements)\n",
    "        \n",
    "        # Calculate probabilities\n",
    "        count_x = sum(w == anchor_word for w in anchor_replacements)\n",
    "        count_y = sum(w == words[other_idx] for w in other_replacements)\n",
    "        count_xy = sum(anchor_replacements[i] == anchor_word and \n",
    "                      other_replacements[i] == words[other_idx] \n",
    "                      for i in range(total))\n",
    "        \n",
    "        P_x = count_x / total\n",
    "        P_y = count_y / total\n",
    "        P_xy = count_xy / total\n",
    "        \n",
    "        # Calculate PMI\n",
    "        if P_x > 0 and P_y > 0 and P_xy > 0:\n",
    "            pmi = math.log2(P_xy / (P_x * P_y))\n",
    "        else:\n",
    "            pmi = float('-inf')\n",
    "        \n",
    "        pmi_scores[other_idx] = {'word': words[other_idx], 'pmi': pmi, \n",
    "                                  'P_x': P_x, 'P_y': P_y, 'P_xy': P_xy}\n",
    "    \n",
    "    return pmi_scores\n",
    "\n",
    "def visualize_pmi(sentence, pmi_scores, anchor_idx):\n",
    "    \"\"\"Visualize PMI with colored words.\"\"\"\n",
    "    words = sentence.split()\n",
    "    \n",
    "    # Normalize PMI values\n",
    "    valid_pmis = [s['pmi'] for s in pmi_scores.values() if s['pmi'] != float('-inf')]\n",
    "    if not valid_pmis:\n",
    "        print(\"No valid PMI scores\")\n",
    "        return\n",
    "    \n",
    "    min_pmi, max_pmi = min(valid_pmis), max(valid_pmis)\n",
    "    pmi_range = max_pmi - min_pmi if max_pmi != min_pmi else 1\n",
    "    \n",
    "    # Color each word\n",
    "    colored_words = []\n",
    "    for i, word in enumerate(words):\n",
    "        if i == anchor_idx:\n",
    "            colored_words.append(colored(word, 'cyan', attrs=['bold']))\n",
    "        elif i in pmi_scores:\n",
    "            pmi = pmi_scores[i]['pmi']\n",
    "            if pmi != float('-inf'):\n",
    "                norm = (pmi - min_pmi) / pmi_range\n",
    "                color = 'green' if norm > 0.66 else 'yellow' if norm > 0.33 else 'red'\n",
    "                colored_words.append(colored(f\"{word}({pmi:.2f})\", color))\n",
    "            else:\n",
    "                colored_words.append(word)\n",
    "        else:\n",
    "            colored_words.append(word)\n",
    "    \n",
    "    print(\"\\n\" + \" \".join(colored_words) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PMI scores\n",
    "pmi_scores = compute_pmi(sentence, all_responses, anchor_word_idx)\n",
    "\n",
    "# Print results\n",
    "words = sentence.lower().split()\n",
    "print(f\"Anchor word: '{words[anchor_word_idx]}'\\n\")\n",
    "for idx in sorted(pmi_scores.keys()):\n",
    "    data = pmi_scores[idx]\n",
    "    print(f\"{data['word']:<15} PMI={data['pmi']:7.3f}  \"\n",
    "          f\"P(x)={data['P_x']:.3f} P(y)={data['P_y']:.3f} P(xy)={data['P_xy']:.3f}\")\n",
    "\n",
    "# Visualize with colors\n",
    "visualize_pmi(sentence, pmi_scores, anchor_word_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMI Results Interpretation (Higher PMI = stronger association)\n",
    "\n",
    "#### Results for \"doctors assess symptoms to diagnose diseases\"\n",
    "- The visualization shows that \"symptoms\" has the strongest semantic bond with \"doctors\" in this sentence\n",
    "\n",
    "**High PMI: Strong Dependency**\n",
    "- **symptoms (1.74)**: had the highest association with \"doctors\", this means that when both are amsked the model frequently generates them to fill the masked words.\n",
    "\n",
    "**Medium PMI: Moderate Dependency**  \n",
    "- **to (1.15)**: Moderate association.\n",
    "\n",
    "**Low PMI: Weak Dependency**\n",
    "- **diseases (0.74)**: Predictable from context but not uniquely tied to \"doctors\"\n",
    "- **diagnose (0.32)**: Despite being less associated with the word doctor (pmi=0.322), it is very predictable (P(y)=0.80). This means that the word itself (\"diagnose\") is very frequent but paired with alternatives to \"doctors\" (physicians, clinicians)\n",
    "\n",
    "**Negative PMI: No Dependency**\n",
    "- **assess (-inf)**: this means the model never generated \"doctors\" when both were masked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. EXERCISE: Try more examples; maybe come up with your own. Report the results.\n",
    "\n",
    "* Try to come up with more examples and, change the anchor word/number of responses, and observe the results. What does the explanation mean? Do you think it's a nice explanation? Why and why not? \n",
    "* What's the limitation of the current method? When does the method fail to explain? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 4\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from tools.command_generator import generate_prompts, prefix_prompt\n",
    "from tools.evaluate_response import get_replacements\n",
    "\n",
    "# PROMPT SAMPLING\n",
    "def run_prompts(model, sentence, anchor_idx, prompts_per_word=20):\n",
    "    prompts = generate_prompts(sentence, anchor_idx)\n",
    "    all_replacements = []\n",
    "\n",
    "    for prompt in prompts:\n",
    "        replacements = []\n",
    "        for _ in tqdm(range(prompts_per_word),\n",
    "                       desc=f\"Processing prompt: {prompt}\",\n",
    "                       leave=False):\n",
    "\n",
    "            response = model.get_response(prefix_prompt(prompt)).strip()\n",
    "            if not response:\n",
    "                continue\n",
    "\n",
    "            replacement = get_replacements(prompt, response)\n",
    "            if replacement:\n",
    "                replacements.append(replacement)\n",
    "\n",
    "        if replacements:\n",
    "            all_replacements.append(replacements)\n",
    "\n",
    "    return all_replacements\n",
    "\n",
    "\n",
    "# VISUALIZE RAW GENERATED SENTENCES\n",
    "def visualize_generated_sentences(all_responses):\n",
    "    print(\"\\nGenerated Sentences:\")\n",
    "    flat = []\n",
    "\n",
    "    for group in all_responses:\n",
    "        for pair in group:\n",
    "            text = \" \".join(pair)\n",
    "            flat.append(text)\n",
    "            print(\" •\", text)\n",
    "\n",
    "    print(f\"\\nTotal generated: {len(flat)}\\n\")\n",
    "    return flat\n",
    "\n",
    "\n",
    "# RUN PMI FOR ALL ANCHOR WORDS IN ONE SENTENCE\n",
    "def run_sentence_experiment(sentence, prompts_per_word=20):\n",
    "    words = sentence.split()\n",
    "    anchor_indices = list(range(len(words)))\n",
    "\n",
    "    print(\"\\n\" + \"#\"*110)\n",
    "    print(f\"ANALYZING SENTENCE:\\n   '{sentence}'\")\n",
    "    print(\"#\"*110)\n",
    "\n",
    "    sentence_results = {}\n",
    "\n",
    "    for anchor_idx in anchor_indices:\n",
    "        anchor_word = words[anchor_idx]\n",
    "\n",
    "        print(\"\\n\" + \"=\"*90)\n",
    "        print(f\"Anchor index: {anchor_idx}   |   Anchor word: '{anchor_word}'\")\n",
    "        print(\"=\"*90)\n",
    "\n",
    "        # Generate model outputs\n",
    "        all_responses = run_prompts(model, sentence, anchor_idx, prompts_per_word)\n",
    "\n",
    "        # Show generated sentences\n",
    "        visualize_generated_sentences(all_responses)\n",
    "\n",
    "        # Compute PMI\n",
    "        pmi_scores = compute_pmi(sentence, all_responses, anchor_idx)\n",
    "\n",
    "        # Print PMI table (no color here)\n",
    "        print(\"\\nPMI Scores:\")\n",
    "        if len(pmi_scores) == 0:\n",
    "            print(\"No valid PMI scores (model did not regenerate expected words).\")\n",
    "        else:\n",
    "            for idx in sorted(pmi_scores.keys()):\n",
    "                d = pmi_scores[idx]\n",
    "                print(f\"{d['word']:<15} PMI={d['pmi']:7.3f}   \"\n",
    "                      f\"P(x)={d['P_x']:.3f}  P(y)={d['P_y']:.3f}  P(xy)={d['P_xy']:.3f}\")\n",
    "\n",
    "        # Save PMI so we can visualize later\n",
    "        sentence_results[anchor_word] = {\n",
    "            \"anchor_idx\": anchor_idx,\n",
    "            \"pmi_scores\": pmi_scores\n",
    "        }\n",
    "\n",
    "    return sentence_results\n",
    "\n",
    "\n",
    "# RUN EXPERIMENT ACROSS MULTIPLE SENTENCES\n",
    "experiment_sentences = [\n",
    "    \"doctors assess symptoms to diagnose diseases\",\n",
    "    \"artificial intelligence transforms modern industries\",\n",
    "    \"children love sweet ice cream on warm summer days\",\n",
    "    \"plants require sunlight and water to grow\",\n",
    "    \"the government announced new policies to support healthcare\",\n",
    "]\n",
    "\n",
    "all_sentence_results = {}\n",
    "\n",
    "for sent in experiment_sentences:\n",
    "    results = run_sentence_experiment(sent, prompts_per_word=20)\n",
    "    all_sentence_results[sent] = results\n",
    "\n",
    "print(\"\\n=== EXERCISE 4 COMPLETE — READY FOR VISUALIZATION ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION FOR  SENTENCES\n",
    "\n",
    "for sentence, anchor_dict in all_sentence_results.items():\n",
    "\n",
    "    print(\"\\n\" + \"#\"*120)\n",
    "    print(f\"VISUALIZATIONS FOR SENTENCE:\\n  '{sentence}'\")\n",
    "    print(\"#\"*120 + \"\\n\")\n",
    "\n",
    "    for anchor_word, info in anchor_dict.items():\n",
    "        anchor_idx = info[\"anchor_idx\"]\n",
    "        pmi_scores = info[\"pmi_scores\"]\n",
    "\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(f\"Anchor word: '{anchor_word}' (index {anchor_idx})\")\n",
    "        print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "        visualize_pmi(sentence, pmi_scores, anchor_idx)\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection on PMI Results and Explanation Quality\n",
    "\n",
    "When we experimented with more sentences, different anchor words, and different numbers of model responses, I observed that the PMI values changed noticeably depending on how often the model regenerated particular word pairs. Words with clear semantic connections, such as doctor and diseases or ice and cream, tended to show higher PMI, while function words like to, and, or new often produced no valid PMI because the model did not reproduce them consistently. Increasing the number of responses made the PMI estimates more stable and less random.\n",
    "\n",
    "The explanation behind PMI is that it reflects how strongly the model associates two words by comparing the probability of generating them together versus independently. A high PMI therefore indicates that the model repeatedly regenerates those words in relation to each other, revealing an underlying learned association.\n",
    "\n",
    "Overall, PMI gives a simple and intuitive explanation because it highlights which words the model considers related. However, it is also limited, since many anchor words do not produce valid PMI, the results are sensitive to sampling noise, and the method does not explain the model’s internal reasoning processes. PMI is therefore helpful for intuition but should not be viewed as a complete explanation of model behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of the PMI-Based Explanation Method\n",
    "\n",
    "While PMI gives a simple way to estimate dependencies between words using a generative LLM, the method comes with several important limitations:\n",
    "\n",
    "**Exact word matching is too rigid**\n",
    "\n",
    "The method only counts a match if the model outputs the exact same word.\n",
    "But LLMs often generate synonyms or variations (e.g., kids vs children), which leads to underestimating true semantic relationships.\n",
    "\n",
    "**Naïve tokenization creates noise**\n",
    "\n",
    "Because the current implementation uses a simple .split(), the method struggles with contractions, punctuation, hyphenated words, and multi word expressions like ice cream or New York.\n",
    "This reduces the accuracy of the PMI associations.\n",
    "\n",
    "**Low sample size leads to unstable probabilities**\n",
    "\n",
    "With around 20 generated completions per masked pair, estimates of P(x), P(y), and P(x,y) can be noisy.\n",
    "A few lucky or unlucky generations can shift PMI ranks significantly.\n",
    "\n",
    "**PMI only captures pairwise relationships**\n",
    "\n",
    "Natural language meaning is often determined by interactions between several words or phrases.\n",
    "PMI cannot model multi word dependencies, syntax, or context beyond two word associations.\n",
    "\n",
    "**LLM biases influence the results**\n",
    "\n",
    "PMI reflects the model’s training distribution and biases.\n",
    "High PMI may reflect frequency biases in training data rather than genuine dependency in the sentence.\n",
    "\n",
    "Overall, PMI gives a simple and interpretable approximation of word dependencies, but its accuracy is limited by tokenization, sampling noise, synonym variation, masking artifacts, and the behavioral nature of the method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bonus Exercises\n",
    "### 5.1 Language pre-processing. \n",
    "In this exercise, we only lower the letters and split sentences into words; there's much more to do to pre-process the language. For example, contractions (*I'll*, *She's*, *world's*), suffix and prefix, compound words (*hard-working*). It's called word tokenization in NLP, and there are some Python packages that can do such work for us, e.g. [*TextBlob*](https://textblob.readthedocs.io/en/dev/). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\"])  # keep tagger & lemmatizer\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess_text(text, keep_stopwords=False, keep_pos=None, remove_punct=True):\n",
    "    \"\"\"\n",
    "    text: single string\n",
    "    keep_stopwords: if False, remove stopwords\n",
    "    keep_pos: None or set like {\"NOUN\",\"VERB\",\"ADJ\"} to filter by POS\n",
    "    remove_punct: whether to drop punctuation tokens\n",
    "    returns: list of normalized tokens (lemmas)\n",
    "    \"\"\"\n",
    "    # basic normalization\n",
    "    text = text.strip()\n",
    "    # optional: expand contractions (can add contraction library)\n",
    "    # remove weird whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if remove_punct and token.is_punct:\n",
    "            continue\n",
    "        if token.like_num:\n",
    "            # choose policy: keep numbers or replace with <NUM>\n",
    "            tokens.append(\"<NUM>\")\n",
    "            continue\n",
    "        if not keep_stopwords and token.is_stop:\n",
    "            continue\n",
    "        if keep_pos and token.pos_ not in keep_pos:\n",
    "            continue\n",
    "        lemma = token.lemma_.lower()\n",
    "        # strip residual punctuation\n",
    "        lemma = re.sub(r'^\\W+|\\W+$', '', lemma)\n",
    "        if lemma:\n",
    "            tokens.append(lemma)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "s = \"She didn't believe the rumor, yet she felt uneasy.\"\n",
    "print(preprocess_text(s, keep_stopwords=False, keep_pos={\"NOUN\",\"VERB\",\"ADJ\"}))\n",
    "# Expected output (approx): ['believe', 'rumor', 'feel', 'uneasy']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Implementation: Advanced Text Preprocessing with spaCy\n",
    "\n",
    "Comparing simple tokenization vs. advanced preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installment and load of spaCy\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Install spaCy model if not already installed\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"spaCy model already loaded\")\n",
    "except:\n",
    "    print(\"Downloading spaCy model...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"spacy\"])\n",
    "    subprocess.run([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"spaCy model installed and loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phill\\miniconda3\\envs\\xai_llm\\lib\\site-packages\\jsonschema\\__init__.py:32: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SIMPLE vs ADVANCED PREPROCESSING COMPARISON\n",
      "======================================================================\n",
      "\n",
      " Original: She didn't believe the rumor, yet she felt uneasy.\n",
      "   Simple:   ['she', \"didn't\", 'believe', 'the', 'rumor,', 'yet', 'she', 'felt', 'uneasy.']\n",
      "   Advanced: ['believe', 'rumor', 'feel', 'uneasy']\n",
      "   With POS: ['believe', 'rumor', 'feel', 'uneasy']\n",
      "\n",
      " Original: The world's best doctors assess patients' symptoms.\n",
      "   Simple:   ['the', \"world's\", 'best', 'doctors', 'assess', \"patients'\", 'symptoms.']\n",
      "   Advanced: ['world', 'good', 'doctor', 'assess', 'patient', 'symptom']\n",
      "   With POS: ['world', 'good', 'doctor', 'assess', 'patient', 'symptom']\n",
      "\n",
      " Original: It's a well-known fact that hard-working people succeed.\n",
      "   Simple:   [\"it's\", 'a', 'well-known', 'fact', 'that', 'hard-working', 'people', 'succeed.']\n",
      "   Advanced: ['know', 'fact', 'hard', 'work', 'people', 'succeed']\n",
      "   With POS: ['know', 'fact', 'work', 'people', 'succeed']\n",
      "\n",
      " Original: I'll be there by 5:30 PM on 12/25/2024.\n",
      "   Simple:   [\"i'll\", 'be', 'there', 'by', '5:30', 'pm', 'on', '12/25/2024.']\n",
      "   Advanced: ['5:30', 'pm', '12/25/2024']\n",
      "   With POS: ['pm']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load spaCy model (disable parser for speed, keep tagger & lemmatizer)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "def preprocess_text(text, keep_stopwords=False, keep_pos=None, remove_punct=True):\n",
    "    \"\"\"\n",
    "    Advanced text preprocessing using spaCy.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Input text to preprocess\n",
    "    keep_stopwords : bool\n",
    "        If False, remove stopwords (the, is, a, etc.)\n",
    "    keep_pos : set or None\n",
    "        Filter by part-of-speech tags (e.g., {\"NOUN\", \"VERB\", \"ADJ\"})\n",
    "    remove_punct : bool\n",
    "        Whether to remove punctuation tokens\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : Normalized tokens (lemmas)\n",
    "    \"\"\"\n",
    "    # Basic normalization\n",
    "    text = text.strip()\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Process with spaCy\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        # Skip punctuation if requested\n",
    "        if remove_punct and token.is_punct:\n",
    "            continue\n",
    "        \n",
    "        # Handle numbers\n",
    "        if token.like_num:\n",
    "            tokens.append(\"<NUM>\")\n",
    "            continue\n",
    "        \n",
    "        # Remove stopwords if requested\n",
    "        if not keep_stopwords and token.is_stop:\n",
    "            continue\n",
    "        \n",
    "        # Filter by POS tag if specified\n",
    "        if keep_pos and token.pos_ not in keep_pos:\n",
    "            continue\n",
    "        \n",
    "        # Get lemma (base form) and lowercase it\n",
    "        lemma = token.lemma_.lower()\n",
    "        \n",
    "        # Strip any residual punctuation at edges\n",
    "        lemma = re.sub(r'^\\W+|\\W+$', '', lemma)\n",
    "        \n",
    "        if lemma:\n",
    "            tokens.append(lemma)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Demonstration examples\n",
    "print(\"=\" * 70)\n",
    "print(\"SIMPLE vs ADVANCED PREPROCESSING COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_sentences = [\n",
    "    \"She didn't believe the rumor, yet she felt uneasy.\",\n",
    "    \"The world's best doctors assess patients' symptoms.\",\n",
    "    \"It's a well-known fact that hard-working people succeed.\",\n",
    "    \"I'll be there by 5:30 PM on 12/25/2024.\"\n",
    "]\n",
    "\n",
    "for sent in test_sentences:\n",
    "    print(f\"\\n Original: {sent}\")\n",
    "    print(f\"   Simple:   {sent.lower().split()}\")\n",
    "    print(f\"   Advanced: {preprocess_text(sent, keep_stopwords=False)}\")\n",
    "    print(f\"   With POS: {preprocess_text(sent, keep_pos={'NOUN', 'VERB', 'ADJ'})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Improvements Demonstrated:\n",
    "\n",
    "1. **Contractions** (`didn't` $\\to$ `not` + `believe`, `I'll` $\\to$ `be`)\n",
    "2. **Possessives** (`patients'` $\\to$ `patient`, `world's` $\\to$ `world`)\n",
    "3. **Lemmatization** (`doctors` $\\to$ `doctor`, `felt` $\\to$ `feel`)\n",
    "4. **Compound words** (`hard-working` $\\to$ separate tokens)\n",
    "5. **Stopword removal** (removes `the`, `a`, `is`, etc.)\n",
    "6. **POS filtering** (keep only NOUN/VERB/ADJ)\n",
    "\n",
    "Now let's apply this to our PMI analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced PMI computation with preprocessing\n",
    "def compute_pmi_enhanced(sentence, all_responses, anchor_idx, use_preprocessing=True):\n",
    "    \"\"\"\n",
    "    Compute PMI with optional advanced preprocessing.\n",
    "    \"\"\"\n",
    "    # Tokenize based on preprocessing choice\n",
    "    if use_preprocessing:\n",
    "        words = preprocess_text(sentence, keep_stopwords=True, remove_punct=False)\n",
    "    else:\n",
    "        words = sentence.lower().split()\n",
    "    \n",
    "    anchor_word = words[anchor_idx]\n",
    "    pmi_scores = {}\n",
    "    \n",
    "    for other_idx in range(len(words)):\n",
    "        if other_idx == anchor_idx:\n",
    "            continue\n",
    "        \n",
    "        pattern_idx = other_idx if other_idx < anchor_idx else other_idx - 1\n",
    "        if pattern_idx >= len(all_responses):\n",
    "            continue\n",
    "            \n",
    "        responses = all_responses[pattern_idx]\n",
    "        if not responses:\n",
    "            continue\n",
    "        \n",
    "        # Process responses with same preprocessing\n",
    "        anchor_replacements = []\n",
    "        other_replacements = []\n",
    "        \n",
    "        for r in responses:\n",
    "            if len(r) == 2:\n",
    "                if use_preprocessing:\n",
    "                    anchor_tokens = preprocess_text(r[0], keep_stopwords=True, remove_punct=False)\n",
    "                    other_tokens = preprocess_text(r[1], keep_stopwords=True, remove_punct=False)\n",
    "                    if anchor_tokens and other_tokens:\n",
    "                        anchor_replacements.append(anchor_tokens[0])\n",
    "                        other_replacements.append(other_tokens[0])\n",
    "                else:\n",
    "                    anchor_replacements.append(r[0].lower())\n",
    "                    other_replacements.append(r[1].lower())\n",
    "        \n",
    "        if not anchor_replacements:\n",
    "            continue\n",
    "            \n",
    "        total = len(anchor_replacements)\n",
    "        \n",
    "        # Calculate probabilities\n",
    "        count_x = sum(w == anchor_word for w in anchor_replacements)\n",
    "        count_y = sum(w == words[other_idx] for w in other_replacements)\n",
    "        count_xy = sum(anchor_replacements[i] == anchor_word and \n",
    "                      other_replacements[i] == words[other_idx] \n",
    "                      for i in range(total))\n",
    "        \n",
    "        P_x = count_x / total if total > 0 else 0\n",
    "        P_y = count_y / total if total > 0 else 0\n",
    "        P_xy = count_xy / total if total > 0 else 0\n",
    "        \n",
    "        # Calculate PMI\n",
    "        if P_x > 0 and P_y > 0 and P_xy > 0:\n",
    "            pmi = math.log2(P_xy / (P_x * P_y))\n",
    "        else:\n",
    "            pmi = float('-inf')\n",
    "        \n",
    "        pmi_scores[other_idx] = {\n",
    "            'word': words[other_idx], \n",
    "            'pmi': pmi, \n",
    "            'P_x': P_x, \n",
    "            'P_y': P_y, \n",
    "            'P_xy': P_xy\n",
    "        }\n",
    "    \n",
    "    return pmi_scores, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: Simple vs Advanced preprocessing\n",
    "test_sentence = \"The doctor's examining patients' symptoms carefully.\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPARISON: Simple vs. Advanced Preprocessing for PMI\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTest sentence: '{test_sentence}'\")\n",
    "print(f\"\\nSimple tokenization: {test_sentence.lower().split()}\")\n",
    "print(f\"Advanced preprocessing: {preprocess_text(test_sentence, keep_stopwords=True, remove_punct=False)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ANALYSIS:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "Benefits of advanced preprocessing:\n",
    "1. **Lemmatization**: 'doctor's' → 'doctor', 'patients' → 'patient'\n",
    "   - Groups inflected forms together for better statistics\n",
    "   \n",
    "2. **Possessive handling**: Removes 's apostrophes properly\n",
    "   - 'doctor's' and 'doctors' both map to 'doctor'\n",
    "   \n",
    "3. **Contraction expansion**: 'didn't' → 'did' + 'not'\n",
    "   - Captures true meaning of negations\n",
    "   \n",
    "4. **Consistent tokenization**: Handles punctuation intelligently\n",
    "   - Doesn't split compound words incorrectly\n",
    "\n",
    "This leads to:\n",
    "More accurate probability estimates (fewer unique tokens)\n",
    "Better matching between original and generated words\n",
    "More meaningful PMI scores\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1 Tasks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Test with your own sentences\n",
    "print(\"=\" * 80)\n",
    "print(\"TASK 1: Testing with Custom Sentences\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Sentences with contractions, possessives, compound words\n",
    "custom_sentences = [\n",
    "    \"She didn't believe the rumor, yet she felt uneasy.\",\n",
    "    \"John's well-known theory about quantum physics won't be forgotten.\",\n",
    "    \"The hard-working scientist's groundbreaking discovery can't be ignored.\",\n",
    "    \"It's a state-of-the-art system that doesn't require maintenance.\",\n",
    "]\n",
    "\n",
    "for i, sent in enumerate(custom_sentences, 1):\n",
    "    print(f\"\\nExample {i}: {sent}\")\n",
    "    print(f\"   Simple:   {sent.lower().split()}\")\n",
    "    print(f\"   Advanced: {preprocess_text(sent, keep_stopwords=False)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Experiment with different preprocessing options\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TASK 2: Experimenting with Different Preprocessing Options\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_text = \"The doctor's examining patients' symptoms carefully.\"\n",
    "\n",
    "print(f\"\\nOriginal sentence: {test_text}\\n\")\n",
    "\n",
    "# Option A: Keep all stopwords\n",
    "print(\"A) With stopwords (keep_stopwords=True):\")\n",
    "print(f\"   {preprocess_text(test_text, keep_stopwords=True, remove_punct=False)}\")\n",
    "\n",
    "# Option B: Remove stopwords\n",
    "print(\"\\nB) Without stopwords (keep_stopwords=False):\")\n",
    "print(f\"   {preprocess_text(test_text, keep_stopwords=False, remove_punct=False)}\")\n",
    "\n",
    "# Option C: Only nouns and verbs\n",
    "print(\"\\nC) Only NOUN + VERB (keep_pos={'NOUN', 'VERB'}):\")\n",
    "print(f\"   {preprocess_text(test_text, keep_stopwords=True, keep_pos={'NOUN', 'VERB'})}\")\n",
    "\n",
    "# Option D: Only adjectives and nouns\n",
    "print(\"\\nD) Only ADJ + NOUN (keep_pos={'ADJ', 'NOUN'}):\")\n",
    "print(f\"   {preprocess_text(test_text, keep_stopwords=True, keep_pos={'ADJ', 'NOUN'})}\")\n",
    "\n",
    "# Option E: Keep punctuation\n",
    "print(\"\\nE) Keep punctuation (remove_punct=False):\")\n",
    "print(f\"   {preprocess_text(test_text, keep_stopwords=False, remove_punct=False)}\")\n",
    "\n",
    "# Option F: Remove punctuation\n",
    "print(\"\\nF) Remove punctuation (remove_punct=True):\")\n",
    "print(f\"   {preprocess_text(test_text, keep_stopwords=False, remove_punct=True)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Summary of Options:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "- keep_stopwords: Controls whether common words (the, is, a) are included\n",
    "- keep_pos: Filter by part-of-speech (NOUN, VERB, ADJ, ADV, etc.)\n",
    "- remove_punct: Whether to remove punctuation tokens\n",
    "\n",
    "Different combinations suit different purposes:\n",
    "• Full preprocessing: best for semantic analysis\n",
    "• POS filtering: emphasizes content words\n",
    "• Keeping stopwords: preserves structure information\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Compare PMI results with and without preprocessing\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TASK 3: PMI Comparison - With vs Without Preprocessing\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load responses if not already loaded\n",
    "import json\n",
    "import math\n",
    "if 'all_responses' not in globals():\n",
    "    try:\n",
    "        with open(\"responses.json\", \"r\") as f:\n",
    "            all_responses = json.load(f)\n",
    "        print(\"Loaded all_responses from responses.json\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: responses.json not found. Please run the prompts first or ensure the file exists.\")\n",
    "        all_responses = []\n",
    "\n",
    "# Use a sentence from earlier that we have responses for\n",
    "comparison_sentence = \"doctors assess symptoms to diagnose diseases\"\n",
    "anchor_idx = 0  # \"doctors\"\n",
    "\n",
    "print(f\"\\nTest sentence: '{comparison_sentence}'\")\n",
    "print(f\"Anchor word (index {anchor_idx}): '{comparison_sentence.split()[anchor_idx]}'\")\n",
    "\n",
    "# Compute PMI both ways\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"WITHOUT Preprocessing (simple tokenization):\")\n",
    "print(\"-\" * 80)\n",
    "pmi_simple, words_simple = compute_pmi_enhanced(comparison_sentence, all_responses, anchor_idx, use_preprocessing=False)\n",
    "for idx in sorted(pmi_simple.keys()):\n",
    "    data = pmi_simple[idx]\n",
    "    pmi_val = data['pmi'] if data['pmi'] != float('-inf') else \"N/A\"\n",
    "    print(f\"  {data['word']:<15} PMI={str(pmi_val):>7}  P(x)={data['P_x']:.3f} P(y)={data['P_y']:.3f} P(xy)={data['P_xy']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"WITH Preprocessing (lemmatization, stopword removal, etc.):\")\n",
    "print(\"-\" * 80)\n",
    "pmi_advanced, words_advanced = compute_pmi_enhanced(comparison_sentence, all_responses, anchor_idx, use_preprocessing=True)\n",
    "for idx in sorted(pmi_advanced.keys()):\n",
    "    data = pmi_advanced[idx]\n",
    "    pmi_val = data['pmi'] if data['pmi'] != float('-inf') else \"N/A\"\n",
    "    print(f\"  {data['word']:<15} PMI={str(pmi_val):>7}  P(x)={data['P_x']:.3f} P(y)={data['P_y']:.3f} P(xy)={data['P_xy']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Comparison Summary:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Simple tokenization found {len(pmi_simple)} word pairs\")\n",
    "print(f\"Advanced preprocessing found {len(pmi_advanced)} word pairs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Task 4: Analysis and Reflection Questions\n",
    "\n",
    "**Question 1: How does preprocessing affect the PMI scores?**\n",
    "\n",
    "**Answer:**\n",
    "- The PMI scores increase because preprocessing groups inflected forms (doctor, doctors, doctor's → doctor), making the anchor word appear more frequently with other words\n",
    "- By reducing vocabulary size (fewer unique tokens), probabilities become less sparse and more reliable\n",
    "- Some PMI values might stabilize because preprocessing normalizes variations in how the model generates responses\n",
    "- Words that appear together in multiple forms now count together, strengthening their association signal\n",
    "\n",
    "**Question 2: When would preprocessing help PMI analysis?**\n",
    "\n",
    "**Answer:**\n",
    "- Better accuracy when words have multiple forms (doctor, doctors, doctor's)\n",
    "- More reliable statistics by grouping related words together\n",
    "- Reduced sparsity (fewer unique tokens)\n",
    "- Better handling of linguistic variations\n",
    "\n",
    "**Question 3: When might preprocessing hurt or be problematic?**\n",
    "\n",
    "**Answer:**\n",
    "- Loss of information when lemmatizing (e.g., \"running\" and \"ran\" both → \"run\")\n",
    "- Removing negations (not, no, didn't) removes important semantic information\n",
    "- Stopword removal loses structural context\n",
    "- Over-aggressive POS filtering might remove important words\n",
    "- Domain-specific terms might be incorrectly lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Practical Demonstration\n",
    "print(\"=\" * 80)\n",
    "print(\"TASK 4: Reflection - Effects of Preprocessing\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Let's create a practical example showing benefits and drawbacks\n",
    "\n",
    "print(\"\\nBENEFIT EXAMPLE: Handling Inflections\")\n",
    "print(\"-\" * 80)\n",
    "example1 = \"The doctors and the doctor's assistant work together.\"\n",
    "print(f\"Original: {example1}\")\n",
    "print(f\"Simple:   {example1.lower().split()}\")\n",
    "print(f\"Advanced: {preprocess_text(example1, keep_stopwords=True)}\")\n",
    "print(\"\\nBenefit: 'doctors', 'doctor's' → all map to 'doctor'\")\n",
    "print(\"  This groups related forms, improving PMI statistics\")\n",
    "\n",
    "print(\"\\n\\nDRAWBACK EXAMPLE: Loss of Negation Information\")\n",
    "print(\"-\" * 80)\n",
    "example2 = \"The doctor didn't diagnose the disease correctly.\"\n",
    "print(f\"Original: {example2}\")\n",
    "print(f\"Simple:   {example2.lower().split()}\")\n",
    "advanced_no_stops = preprocess_text(example2, keep_stopwords=False)\n",
    "print(f\"Advanced (stopwords removed): {advanced_no_stops}\")\n",
    "advanced_keep_stops = preprocess_text(example2, keep_stopwords=True)\n",
    "print(f\"Advanced (stopwords kept):    {advanced_keep_stops}\")\n",
    "print(\"\\nDrawback: Removing 'didn't' loses the negation!\")\n",
    "print(\"  'didn't diagnose' → 'diagnose' loses semantic meaning\")\n",
    "\n",
    "print(\"\\n\\nBENEFIT EXAMPLE: Reducing Sparsity\")\n",
    "print(\"-\" * 80)\n",
    "example3 = \"running, runs, run, runner - different forms of the same concept\"\n",
    "print(f\"Original forms: running, runs, run, runner\")\n",
    "lemmatized = [preprocess_text(word, keep_stopwords=True)[0] if preprocess_text(word, keep_stopwords=True) else word \n",
    "              for word in [\"running\", \"runs\", \"run\", \"runner\"]]\n",
    "print(f\"Lemmatized:    {lemmatized}\")\n",
    "print(\"\\nBenefit: All group to 'run', reducing vocabulary size\")\n",
    "print(\"  Fewer unique tokens = better probability estimates\")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"TAKEAWAYS:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "Preprocessing HELPS when:\n",
    "  1. Handling grammatical variations (plurals, tenses, possessives)\n",
    "  2. Reducing sparsity (fewer unique tokens for better statistics)\n",
    "  3. Normalizing text from different sources\n",
    "  4. Focusing on content words (POS filtering)\n",
    "\n",
    "Preprocessing HURTS when:\n",
    "  1. Important semantic information is lost (negations, intensifiers)\n",
    "  2. Domain-specific terminology is incorrectly normalized\n",
    "  3. Removing context needed for interpretation\n",
    "  4. Over-aggressive filtering removes meaningful words\n",
    "\n",
    "RECOMMENDATION FOR PMI ANALYSIS:\n",
    "Use selective preprocessing:\n",
    "  - Keep lemmatization (group related forms)\n",
    "  - Keep stopwords (preserve structure)\n",
    "  - Avoid aggressive stopword removal\n",
    "  - Consider task-specific POS filtering\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Better word matching\n",
    "In the above example of\n",
    "> Tokyo is the capital of Japan and a popular metropolis in the world.\n",
    "\n",
    "GenAI never gives the specific word 'metropolis' when masking it out; instead, sometimes it provides words like 'city', which is not the same word but has a similar meaning. Instead of measuring the exact matching of certain words (i.e. 0 or 1), we can also measure the similarity of two words, e.g. the cosine similarity in word embedding, which ranges from 0 to 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXERCISE 5.2: Better Word Matching with Word Embeddings\n",
      "================================================================================\n",
      "Word2Vec model loaded successfully\n",
      "  Vocabulary size: 3000000 words\n",
      "  Vector dimensions: 300\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Example: Similarity between 'metropolis' and 'city'\n",
      "--------------------------------------------------------------------------------\n",
      "  similarity('metropolis', 'city') = 0.5717 (normalized: 0.7859)\n",
      "  similarity('metropolis', 'metropolis') = 1.0000 (normalized: 1.0000)\n",
      "  similarity('metropolis', 'town') = 0.3758 (normalized: 0.6879)\n",
      "  similarity('metropolis', 'village') = 0.3228 (normalized: 0.6614)\n",
      "  similarity('metropolis', 'urban') = 0.5147 (normalized: 0.7574)\n",
      "  similarity('city', 'town') = 0.6724 (normalized: 0.8362)\n",
      "  similarity('Japan', 'Tokyo') = 0.7002 (normalized: 0.8501)\n",
      "  similarity('capital', 'city') = 0.3281 (normalized: 0.6641)\n",
      "Word2Vec model loaded successfully\n",
      "  Vocabulary size: 3000000 words\n",
      "  Vector dimensions: 300\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Example: Similarity between 'metropolis' and 'city'\n",
      "--------------------------------------------------------------------------------\n",
      "  similarity('metropolis', 'city') = 0.5717 (normalized: 0.7859)\n",
      "  similarity('metropolis', 'metropolis') = 1.0000 (normalized: 1.0000)\n",
      "  similarity('metropolis', 'town') = 0.3758 (normalized: 0.6879)\n",
      "  similarity('metropolis', 'village') = 0.3228 (normalized: 0.6614)\n",
      "  similarity('metropolis', 'urban') = 0.5147 (normalized: 0.7574)\n",
      "  similarity('city', 'town') = 0.6724 (normalized: 0.8362)\n",
      "  similarity('Japan', 'Tokyo') = 0.7002 (normalized: 0.8501)\n",
      "  similarity('capital', 'city') = 0.3281 (normalized: 0.6641)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.2: Better word matching using word embeddings\n",
    "# Instead of exact matching (0 or 1), we use cosine similarity from word embeddings (0 to 1)\n",
    "\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXERCISE 5.2: Better Word Matching with Word Embeddings\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load pre-trained word embeddings (Word2Vec trained on Google News)\n",
    "try:\n",
    "    word_vectors = api.load('word2vec-google-news-300')\n",
    "    print(\"Word2Vec model loaded successfully\")\n",
    "    print(f\"  Vocabulary size: {len(word_vectors)} words\")\n",
    "    print(f\"  Vector dimensions: {word_vectors.vector_size}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading word vectors: {e}\")\n",
    "    print(\"Attempting to use a smaller model...\")\n",
    "    word_vectors = api.load('glove-wiki-gigaword-50')\n",
    "    print(\"GloVe model loaded successfully\")\n",
    "\n",
    "# Test with the metropolis/city example\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Example: Similarity between 'metropolis' and 'city'\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "test_words = [\n",
    "    ('metropolis', 'city'),\n",
    "    ('metropolis', 'metropolis'),\n",
    "    ('metropolis', 'town'),\n",
    "    ('metropolis', 'village'),\n",
    "    ('metropolis', 'urban'),\n",
    "    ('city', 'town'),\n",
    "    ('Japan', 'Tokyo'),\n",
    "    ('capital', 'city')\n",
    "]\n",
    "\n",
    "for word1, word2 in test_words:\n",
    "    try:\n",
    "        similarity = word_vectors.similarity(word1, word2)\n",
    "        # Normalize to [0, 1] range (cosine similarity is in [-1, 1])\n",
    "        normalized_sim = (similarity + 1) / 2\n",
    "        print(f\"  similarity('{word1}', '{word2}') = {similarity:.4f} (normalized: {normalized_sim:.4f})\")\n",
    "    except KeyError as e:\n",
    "        print(f\"  similarity('{word1}', '{word2}') = N/A (word not in vocabulary)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "- Exact matches have similarity ≈ 1.0\n",
    "- Semantically similar words (metropolis/city) have high similarity (>0.6)\n",
    "- Less similar words have lower similarity scores\n",
    "- This allows us to give partial credit for similar words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PMI with Word Embedding Similarity - Function Defined\n",
      "================================================================================\n",
      "compute_pmi_with_similarity() function ready to use\n"
     ]
    }
   ],
   "source": [
    "# Enhanced PMI computation using word embedding similarity\n",
    "def compute_pmi_with_similarity(sentence, all_responses, anchor_idx, word_vectors, \n",
    "                                use_preprocessing=True, similarity_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Compute PMI using word embedding similarity instead of exact matches.\n",
    "    \n",
    "    Parameters:\n",
    "    - sentence: input sentence\n",
    "    - all_responses: list of model responses for masked positions\n",
    "    - anchor_idx: index of the anchor word\n",
    "    - word_vectors: loaded word embedding model (e.g., Word2Vec)\n",
    "    - use_preprocessing: whether to apply lemmatization/preprocessing\n",
    "    - similarity_threshold: minimum similarity to consider (default 0.5)\n",
    "    \n",
    "    Returns:\n",
    "    - pmi_scores: dictionary of PMI scores for each word\n",
    "    - words: tokenized sentence\n",
    "    \"\"\"\n",
    "    import math\n",
    "    \n",
    "    # Tokenize based on preprocessing choice\n",
    "    if use_preprocessing:\n",
    "        words = preprocess_text(sentence, keep_stopwords=True, remove_punct=False)\n",
    "    else:\n",
    "        words = sentence.lower().split()\n",
    "    \n",
    "    anchor_word = words[anchor_idx]\n",
    "    pmi_scores = {}\n",
    "    \n",
    "    # Helper function to compute similarity with fallback\n",
    "    def get_similarity(w1, w2):\n",
    "        \"\"\"Get similarity between two words, with fallback for OOV words\"\"\"\n",
    "        try:\n",
    "            # Cosine similarity from word vectors (range: -1 to 1)\n",
    "            sim = word_vectors.similarity(w1, w2)\n",
    "            # Normalize to [0, 1] range\n",
    "            return max(0, (sim + 1) / 2)\n",
    "        except KeyError:\n",
    "            # If word not in vocabulary, use exact match (0 or 1)\n",
    "            return 1.0 if w1 == w2 else 0.0\n",
    "    \n",
    "    for other_idx in range(len(words)):\n",
    "        if other_idx == anchor_idx:\n",
    "            continue\n",
    "        \n",
    "        pattern_idx = other_idx if other_idx < anchor_idx else other_idx - 1\n",
    "        if pattern_idx >= len(all_responses):\n",
    "            continue\n",
    "            \n",
    "        responses = all_responses[pattern_idx]\n",
    "        if not responses:\n",
    "            continue\n",
    "        \n",
    "        # Process responses with same preprocessing\n",
    "        anchor_replacements = []\n",
    "        other_replacements = []\n",
    "        \n",
    "        for r in responses:\n",
    "            if len(r) == 2:\n",
    "                if use_preprocessing:\n",
    "                    anchor_tokens = preprocess_text(r[0], keep_stopwords=True, remove_punct=False)\n",
    "                    other_tokens = preprocess_text(r[1], keep_stopwords=True, remove_punct=False)\n",
    "                    if anchor_tokens and other_tokens:\n",
    "                        anchor_replacements.append(anchor_tokens[0])\n",
    "                        other_replacements.append(other_tokens[0])\n",
    "                else:\n",
    "                    anchor_replacements.append(r[0].lower())\n",
    "                    other_replacements.append(r[1].lower())\n",
    "        \n",
    "        if not anchor_replacements:\n",
    "            continue\n",
    "            \n",
    "        total = len(anchor_replacements)\n",
    "        \n",
    "        # Calculate SOFT probabilities using similarity scores\n",
    "        # Instead of hard 0/1 matching, we use similarity scores\n",
    "        similarity_x = sum(get_similarity(w, anchor_word) for w in anchor_replacements)\n",
    "        similarity_y = sum(get_similarity(w, words[other_idx]) for w in other_replacements)\n",
    "        similarity_xy = sum(\n",
    "            get_similarity(anchor_replacements[i], anchor_word) * \n",
    "            get_similarity(other_replacements[i], words[other_idx]) \n",
    "            for i in range(total)\n",
    "        )\n",
    "        \n",
    "        # Soft probabilities (normalized by total count)\n",
    "        P_x = similarity_x / total if total > 0 else 0\n",
    "        P_y = similarity_y / total if total > 0 else 0\n",
    "        P_xy = similarity_xy / total if total > 0 else 0\n",
    "        \n",
    "        # Calculate PMI\n",
    "        if P_x > 0 and P_y > 0 and P_xy > 0:\n",
    "            pmi = math.log2(P_xy / (P_x * P_y))\n",
    "        else:\n",
    "            pmi = float('-inf')\n",
    "        \n",
    "        pmi_scores[other_idx] = {\n",
    "            'word': words[other_idx], \n",
    "            'pmi': pmi, \n",
    "            'P_x': P_x, \n",
    "            'P_y': P_y, \n",
    "            'P_xy': P_xy,\n",
    "            'similarity_x': similarity_x / total if total > 0 else 0,\n",
    "            'similarity_y': similarity_y / total if total > 0 else 0\n",
    "        }\n",
    "    \n",
    "    return pmi_scores, words\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PMI with Word Embedding Similarity - Function Defined\")\n",
    "print(\"=\" * 80)\n",
    "print(\"compute_pmi_with_similarity() function ready to use\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key improvements:\n",
    "- Uses cosine similarity instead of exact matching\n",
    "- Gives partial credit for semantically similar words\n",
    "- Handles out-of-vocabulary words gracefully\n",
    "- Better captures semantic associations in PMI scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARISON: Exact Matching vs Word Embedding Similarity\n",
      "================================================================================\n",
      "\n",
      "Test sentence: 'doctors assess symptoms to diagnose diseases'\n",
      "Anchor word (index 0): 'doctors'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "METHOD 1: EXACT MATCHING (original approach)\n",
      "--------------------------------------------------------------------------------\n",
      "  assess          PMI=    N/A  P(x)=0.333 P(y)=0.000 P(xy)=0.000\n",
      "  symptom         PMI=    N/A  P(x)=0.000 P(y)=0.333 P(xy)=0.000\n",
      "  to              PMI=    N/A  P(x)=0.000 P(y)=0.667 P(xy)=0.000\n",
      "  diagnose        PMI=    N/A  P(x)=0.000 P(y)=0.000 P(xy)=0.000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "METHOD 2: SIMILARITY-BASED MATCHING (with word embeddings)\n",
      "--------------------------------------------------------------------------------\n",
      "  assess          PMI=  0.006  P(x)=0.854 P(y)=0.805 P(xy)=0.690  avg_sim=0.829\n",
      "  symptom         PMI=  0.002  P(x)=0.547 P(y)=0.765 P(xy)=0.419  avg_sim=0.656\n",
      "  to              PMI=  0.019  P(x)=0.573 P(y)=0.667 P(xy)=0.387  avg_sim=0.620\n",
      "  diagnose        PMI=  0.005  P(x)=0.559 P(y)=0.649 P(xy)=0.364  avg_sim=0.604\n"
     ]
    }
   ],
   "source": [
    "# Demonstration: Compare exact matching vs similarity-based matching\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPARISON: Exact Matching vs Word Embedding Similarity\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use the comparison sentence from earlier\n",
    "comparison_sentence = \"doctors assess symptoms to diagnose diseases\"\n",
    "anchor_idx = 0  # \"doctors\"\n",
    "\n",
    "print(f\"\\nTest sentence: '{comparison_sentence}'\")\n",
    "print(f\"Anchor word (index {anchor_idx}): '{comparison_sentence.split()[anchor_idx]}'\")\n",
    "\n",
    "# Make sure we have responses loaded\n",
    "if 'all_responses' not in globals() or not all_responses:\n",
    "    print(\"\\n⚠ Warning: No responses loaded. Using example responses for demonstration.\")\n",
    "    # Create example responses for demonstration\n",
    "    all_responses = [\n",
    "        [['physicians', 'evaluate'], ['doctors', 'examine'], ['medical professionals', 'check']],\n",
    "        [['examine', 'indicators'], ['evaluate', 'signs'], ['assess', 'symptoms']],\n",
    "        [['signs', 'for'], ['indicators', 'to'], ['symptoms', 'to']],\n",
    "        [['identify', 'illnesses'], ['detect', 'conditions'], ['diagnose', 'diseases']]\n",
    "    ]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"METHOD 1: EXACT MATCHING (original approach)\")\n",
    "print(\"-\" * 80)\n",
    "try:\n",
    "    pmi_exact, words_exact = compute_pmi_enhanced(comparison_sentence, all_responses, anchor_idx, use_preprocessing=True)\n",
    "    for idx in sorted(pmi_exact.keys()):\n",
    "        data = pmi_exact[idx]\n",
    "        pmi_val = f\"{data['pmi']:.3f}\" if data['pmi'] != float('-inf') else \"N/A\"\n",
    "        print(f\"  {data['word']:<15} PMI={pmi_val:>7}  P(x)={data['P_x']:.3f} P(y)={data['P_y']:.3f} P(xy)={data['P_xy']:.3f}\")\n",
    "except NameError:\n",
    "    print(\"  compute_pmi_enhanced function not found. Skipping exact matching comparison.\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"METHOD 2: SIMILARITY-BASED MATCHING (with word embeddings)\")\n",
    "print(\"-\" * 80)\n",
    "pmi_similarity, words_similarity = compute_pmi_with_similarity(\n",
    "    comparison_sentence, all_responses, anchor_idx, word_vectors, use_preprocessing=True\n",
    ")\n",
    "for idx in sorted(pmi_similarity.keys()):\n",
    "    data = pmi_similarity[idx]\n",
    "    pmi_val = f\"{data['pmi']:.3f}\" if data['pmi'] != float('-inf') else \"N/A\"\n",
    "    avg_sim = (data['similarity_x'] + data['similarity_y']) / 2\n",
    "    print(f\"  {data['word']:<15} PMI={pmi_val:>7}  P(x)={data['P_x']:.3f} P(y)={data['P_y']:.3f} P(xy)={data['P_xy']:.3f}  avg_sim={avg_sim:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Differences:\n",
    "\n",
    "**EXACT MATCHING:**\n",
    "- Only counts perfect word matches (doctors == doctors → 1, else → 0)\n",
    "- Misses semantically similar words (doctors vs physicians)\n",
    "- Lower probability estimates due to strict matching\n",
    "- May produce -inf PMI when no exact matches occur\n",
    "\n",
    "**SIMILARITY-BASED MATCHING:**\n",
    "- Uses cosine similarity from word embeddings (0 to 1 range)\n",
    "- Gives partial credit for similar words (doctors/physicians ≈ 0.7)\n",
    "- Higher probability estimates by capturing semantic similarity\n",
    "- More robust PMI scores even when exact matches are rare\n",
    "- Better reflects semantic associations in the data\n",
    "\n",
    "**WHEN TO USE EACH:**\n",
    "- Exact matching: When precise word choice matters (e.g., sentiment analysis)\n",
    "- Similarity matching: When semantic meaning matters (e.g., topic modeling, Q&A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PRACTICAL EXAMPLE: Handling 'metropolis' vs 'city'\n",
      "================================================================================\n",
      "\n",
      "Original sentence: 'Tokyo is the capital of Japan and a popular metropolis in the world'\n",
      "Anchor word (index 6): 'and'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SCENARIO: Model generates 'city' instead of 'metropolis'\n",
      "--------------------------------------------------------------------------------\n",
      "Sample model responses when masking 'metropolis':\n",
      "  - Generated: 'city' (not exact match)\n",
      "  - Generated: 'city' (not exact match)\n",
      "  - Generated: 'urban area' (not exact match)\n",
      "\n",
      "Word similarity analysis:\n",
      "  similarity('metropolis', 'city') = 0.5717 (normalized: 0.7859)\n",
      "  similarity('metropolis', 'urban') = 0.5147 (normalized: 0.7574)\n",
      "  similarity('metropolis', 'area') = 0.3758 (normalized: 0.6879)\n",
      "  similarity('metropolis', 'town') = 0.3758 (normalized: 0.6879)\n",
      "  similarity('metropolis', 'metropolis') = 1.0000 (normalized: 1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Practical Example: The \"metropolis\" vs \"city\" case\n",
    "print(\"=\" * 80)\n",
    "print(\"PRACTICAL EXAMPLE: Handling 'metropolis' vs 'city'\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "example_sentence = \"Tokyo is the capital of Japan and a popular metropolis in the world\"\n",
    "example_anchor_idx = 6  # \"metropolis\"\n",
    "\n",
    "print(f\"\\nOriginal sentence: '{example_sentence}'\")\n",
    "words_example = example_sentence.lower().split()\n",
    "print(f\"Anchor word (index {example_anchor_idx}): '{words_example[example_anchor_idx]}'\")\n",
    "\n",
    "# Simulate model responses where it generates \"city\" instead of \"metropolis\"\n",
    "example_responses = [\n",
    "    [['Tokyo', 'Tokyo'], ['Tokyo', 'Tokyo'], ['Tokyo', 'Tokyo']],  # idx 0: Tokyo\n",
    "    [['is', 'is'], ['is', 'is'], ['is', 'is']],  # idx 1: is\n",
    "    [['the', 'the'], ['the', 'the'], ['the', 'the']],  # idx 2: the\n",
    "    [['capital', 'capital'], ['capital', 'city'], ['capital', 'capital']],  # idx 3: capital\n",
    "    [['of', 'of'], ['of', 'of'], ['of', 'of']],  # idx 4: of\n",
    "    [['Japan', 'Japan'], ['Japan', 'Japan'], ['Japan', 'Japan']],  # idx 5: Japan\n",
    "    # idx 6 is the anchor (metropolis) - skipped\n",
    "    [['city', 'city'], ['city', 'Tokyo'], ['urban area', 'Japan']],  # responses when masking 'metropolis'\n",
    "    [['in', 'in'], ['in', 'in'], ['in', 'in']],  # idx 7: in\n",
    "    [['the', 'the'], ['the', 'the'], ['the', 'the']],  # idx 8: the\n",
    "    [['world', 'world'], ['world', 'world'], ['world', 'globe']],  # idx 9: world\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"SCENARIO: Model generates 'city' instead of 'metropolis'\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Sample model responses when masking 'metropolis':\")\n",
    "print(\"  - Generated: 'city' (not exact match)\")\n",
    "print(\"  - Generated: 'city' (not exact match)\")\n",
    "print(\"  - Generated: 'urban area' (not exact match)\")\n",
    "\n",
    "# Check similarity between metropolis and generated words\n",
    "print(\"\\nWord similarity analysis:\")\n",
    "generated_words = ['city', 'urban', 'area', 'town', 'metropolis']\n",
    "for word in generated_words:\n",
    "    try:\n",
    "        sim = word_vectors.similarity('metropolis', word)\n",
    "        normalized = (sim + 1) / 2\n",
    "        print(f\"  similarity('metropolis', '{word}') = {sim:.4f} (normalized: {normalized:.4f})\")\n",
    "    except KeyError:\n",
    "        print(f\"  similarity('metropolis', '{word}') = N/A (not in vocabulary)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: How Each Method Handles This\n",
    "\n",
    "**1. EXACT MATCHING:**\n",
    "- 'metropolis' vs 'city': Match score = 0 (no match)\n",
    "- 'metropolis' vs 'urban': Match score = 0 (no match)\n",
    "- Result: Lower PMI, underestimates semantic association\n",
    "\n",
    "**2. SIMILARITY-BASED MATCHING:**\n",
    "- 'metropolis' vs 'city': Match score ≈ 0.786 (semantic similarity)\n",
    "- 'metropolis' vs 'urban': Match score ≈ 0.757 (semantic similarity)\n",
    "- Result: Higher PMI, better captures semantic association\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "Word embedding similarity provides a more nuanced understanding of word associations.\n",
    "\n",
    "The similarity-based approach gives partial credit for semantically related words (e.g., 'city' and 'metropolis'), making it more robust to variations in model output. This better reflects semantic associations compared to exact string matching.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
